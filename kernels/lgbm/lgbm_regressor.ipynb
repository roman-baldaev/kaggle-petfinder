{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import lightgbm as lgb\n",
    "import scipy as sp\n",
    "\n",
    "from functools import partial\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 322"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"../../input\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(input_path, 'train/train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(os.path.join(input_path, 'test/test.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking on label balance in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "adoption_speed_hist = train_df.hist('AdoptionSpeed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quadratic weighted kappa score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following 3 functions have been taken from Ben Hamner's github repository\n",
    "# https://github.com/benhamner/Metrics\n",
    "def confusion_matrix(rater_a, rater_b, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Returns the confusion matrix between rater's ratings\n",
    "    \"\"\"\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(rater_a + rater_b)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(rater_a + rater_b)\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    conf_mat = [[0 for i in range(num_ratings)]\n",
    "                for j in range(num_ratings)]\n",
    "    for a, b in zip(rater_a, rater_b):\n",
    "        conf_mat[a - min_rating][b - min_rating] += 1\n",
    "    return conf_mat\n",
    "\n",
    "\n",
    "def histogram(ratings, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Returns the counts of each type of rating that a rater made\n",
    "    \"\"\"\n",
    "    if min_rating is None:\n",
    "        min_rating = min(ratings)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(ratings)\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    hist_ratings = [0 for x in range(num_ratings)]\n",
    "    for r in ratings:\n",
    "        hist_ratings[r - min_rating] += 1\n",
    "    return hist_ratings\n",
    "\n",
    "\n",
    "def quadratic_weighted_kappa(y, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the quadratic weighted kappa\n",
    "    axquadratic_weighted_kappa calculates the quadratic weighted kappa\n",
    "    value, which is a measure of inter-rater agreement between two raters\n",
    "    that provide discrete numeric ratings.  Potential values range from -1\n",
    "    (representing complete disagreement) to 1 (representing complete\n",
    "    agreement).  A kappa value of 0 is expected if all agreement is due to\n",
    "    chance.\n",
    "    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n",
    "    each correspond to a list of integer ratings.  These lists must have the\n",
    "    same length.\n",
    "    The ratings should be integers, and it is assumed that they contain\n",
    "    the complete range of possible ratings.\n",
    "    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n",
    "    is the minimum possible rating, and max_rating is the maximum possible\n",
    "    rating\n",
    "    \"\"\"\n",
    "    rater_a = y\n",
    "    rater_b = y_pred\n",
    "    min_rating=None\n",
    "    max_rating=None\n",
    "    rater_a = np.array(rater_a, dtype=int)\n",
    "    rater_b = np.array(rater_b, dtype=int)\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(min(rater_a), min(rater_b))\n",
    "    if max_rating is None:\n",
    "        max_rating = max(max(rater_a), max(rater_b))\n",
    "    conf_mat = confusion_matrix(rater_a, rater_b,\n",
    "                                min_rating, max_rating)\n",
    "    num_ratings = len(conf_mat)\n",
    "    num_scored_items = float(len(rater_a))\n",
    "\n",
    "    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n",
    "    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n",
    "\n",
    "    numerator = 0.0\n",
    "    denominator = 0.0\n",
    "\n",
    "    for i in range(num_ratings):\n",
    "        for j in range(num_ratings):\n",
    "            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n",
    "                              / num_scored_items)\n",
    "            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n",
    "            numerator += d * conf_mat[i][j] / num_scored_items\n",
    "            denominator += d * expected_count / num_scored_items\n",
    "\n",
    "    return (1.0 - numerator / denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficients optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizedRounder(object):\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _kappa_loss(self, coef, X, y):\n",
    "        X_p = np.copy(X)\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]:\n",
    "                X_p[i] = 0\n",
    "            elif pred >= coef[0] and pred < coef[1]:\n",
    "                X_p[i] = 1\n",
    "            elif pred >= coef[1] and pred < coef[2]:\n",
    "                X_p[i] = 2\n",
    "            elif pred >= coef[2] and pred < coef[3]:\n",
    "                X_p[i] = 3\n",
    "            else:\n",
    "                X_p[i] = 4\n",
    "\n",
    "        ll = quadratic_weighted_kappa(y, X_p)\n",
    "        return -ll\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        loss_partial = partial(self._kappa_loss, X=X, y=y)\n",
    "        initial_coef = [0.5, 1.5, 2.5, 3.5]\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        X_p = np.copy(X)\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]:\n",
    "                X_p[i] = 0\n",
    "            elif pred >= coef[0] and pred < coef[1]:\n",
    "                X_p[i] = 1\n",
    "            elif pred >= coef[1] and pred < coef[2]:\n",
    "                X_p[i] = 2\n",
    "            elif pred >= coef[2] and pred < coef[3]:\n",
    "                X_p[i] = 3\n",
    "            else:\n",
    "                X_p[i] = 4\n",
    "        return X_p\n",
    "\n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate features based on 'Name' ('No_name',  'Bad_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Name'] = train_df['Name'].fillna('No Name')\n",
    "test_df['Name'] = test_df['Name'].fillna('No Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['No_name'] = 0\n",
    "train_df.loc[(train_df['Name'] == 'No Name') | \n",
    "             (train_df['Name'] == 'No Name Yet'), 'No_name'] = 1\n",
    "test_df['No_name'] = 0\n",
    "test_df.loc[(test_df['Name'] == 'No Name')| \n",
    "             (test_df['Name'] == 'No Name Yet'), 'No_name'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Bad_name'] = 0\n",
    "train_df.loc[train_df['Name'].apply(lambda x: len(str(x))) < 3, 'Bad_name'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Bad_name'] = 0\n",
    "test_df.loc[test_df['Name'].apply(lambda x: len(str(x))) < 3, 'Bad_name'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Breed2</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>Color3</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>...</th>\n",
       "      <th>Fee</th>\n",
       "      <th>State</th>\n",
       "      <th>RescuerID</th>\n",
       "      <th>VideoAmt</th>\n",
       "      <th>Description</th>\n",
       "      <th>PetID</th>\n",
       "      <th>PhotoAmt</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "      <th>No_name</th>\n",
       "      <th>Bad_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Nibble</td>\n",
       "      <td>3</td>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>41326</td>\n",
       "      <td>8480853f516546f6cf33aa88cd76c379</td>\n",
       "      <td>0</td>\n",
       "      <td>Nibble is a 3+ month old ball of cuteness. He ...</td>\n",
       "      <td>86e1089a3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>No Name Yet</td>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>41401</td>\n",
       "      <td>3082c7125d8fb66f7dd4bff4192c8b14</td>\n",
       "      <td>0</td>\n",
       "      <td>I just found it alone yesterday near my apartm...</td>\n",
       "      <td>6296e909a</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Brisco</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>fa90fa5b1ee11c86938398b60abc32cb</td>\n",
       "      <td>0</td>\n",
       "      <td>Their pregnant mother was dumped by her irresp...</td>\n",
       "      <td>3422e4906</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Miko</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>150</td>\n",
       "      <td>41401</td>\n",
       "      <td>9238e4f44c71a75282e62f7136c6b240</td>\n",
       "      <td>0</td>\n",
       "      <td>Good guard dog, very alert, active, obedience ...</td>\n",
       "      <td>5842f1ff5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>95481e953f8aed9ec3d16fc4509537e8</td>\n",
       "      <td>0</td>\n",
       "      <td>This handsome yet cute boy is up for adoption....</td>\n",
       "      <td>850a43f90</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type         Name  Age  Breed1  Breed2  Gender  Color1  Color2  Color3  \\\n",
       "0     2       Nibble    3     299       0       1       1       7       0   \n",
       "1     2  No Name Yet    1     265       0       1       1       2       0   \n",
       "2     1       Brisco    1     307       0       1       2       7       0   \n",
       "3     1         Miko    4     307       0       2       1       2       0   \n",
       "4     1       Hunter    1     307       0       1       1       0       0   \n",
       "\n",
       "   MaturitySize    ...     Fee  State                         RescuerID  \\\n",
       "0             1    ...     100  41326  8480853f516546f6cf33aa88cd76c379   \n",
       "1             2    ...       0  41401  3082c7125d8fb66f7dd4bff4192c8b14   \n",
       "2             2    ...       0  41326  fa90fa5b1ee11c86938398b60abc32cb   \n",
       "3             2    ...     150  41401  9238e4f44c71a75282e62f7136c6b240   \n",
       "4             2    ...       0  41326  95481e953f8aed9ec3d16fc4509537e8   \n",
       "\n",
       "   VideoAmt                                        Description      PetID  \\\n",
       "0         0  Nibble is a 3+ month old ball of cuteness. He ...  86e1089a3   \n",
       "1         0  I just found it alone yesterday near my apartm...  6296e909a   \n",
       "2         0  Their pregnant mother was dumped by her irresp...  3422e4906   \n",
       "3         0  Good guard dog, very alert, active, obedience ...  5842f1ff5   \n",
       "4         0  This handsome yet cute boy is up for adoption....  850a43f90   \n",
       "\n",
       "   PhotoAmt  AdoptionSpeed No_name  Bad_name  \n",
       "0       1.0              2       0         0  \n",
       "1       2.0              0       1         0  \n",
       "2       7.0              3       0         0  \n",
       "3       8.0              2       0         0  \n",
       "4       3.0              2       0         0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add features from sentiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sentiment_features(df, id_column_name, sent_dir):\n",
    "    doc_sent_mag = []\n",
    "    doc_sent_score = []\n",
    "    not_found_count = 0\n",
    "    \n",
    "    for id in tqdm(df[id_column_name]):\n",
    "        try:\n",
    "            with open(os.path.join(sent_dir, id + '.json'), 'r') as f:\n",
    "                sentiment = json.load(f)\n",
    "            doc_sent_mag.append(sentiment['documentSentiment']['magnitude'])\n",
    "            doc_sent_score.append(sentiment['documentSentiment']['score'])\n",
    "        except Exception as e:\n",
    "            not_found_count += 1\n",
    "            doc_sent_mag.append(-1)\n",
    "            doc_sent_score.append(-1)\n",
    "    df.loc[:, 'doc_sent_mag'] = doc_sent_mag\n",
    "    df.loc[:, 'doc_sent_score'] = doc_sent_score\n",
    "    print(\"Number of all objects: {}\".format(df.shape[0]))\n",
    "    print(\"Not found: {}\".format(not_found_count))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14993/14993 [00:04<00:00, 3619.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all objects: 14993\n",
      "Not found: 551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df = add_sentiment_features(train_df, 'PetID', input_path + '/train_sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3948/3948 [00:01<00:00, 3343.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all objects: 3948\n",
      "Not found: 133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_df = add_sentiment_features(test_df, 'PetID', input_path + '/test_sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_image_metadata_features(df, id_column_name, metadata_dir):\n",
    "    vertex_xs = []\n",
    "    vertex_ys = []\n",
    "    bounding_confidences = []\n",
    "    bounding_importance_fracs = []\n",
    "    dominant_blues = []\n",
    "    dominant_greens = []\n",
    "    dominant_reds = []\n",
    "    dominant_pixel_fracs = []\n",
    "    dominant_scores = []\n",
    "    label_scores = []\n",
    "    nf_count = 0\n",
    "    nl_count = 0\n",
    "    \n",
    "    df_id = df[id_column_name]\n",
    "    for pet in tqdm(df_id):\n",
    "        try:\n",
    "            with open(os.path.join(metadata_dir, pet + '-1.json'), 'r') as f:\n",
    "                data = json.load(f)\n",
    "            vertex_x = data['cropHintsAnnotation']['cropHints'][0]['boundingPoly']['vertices'][2]['x']\n",
    "            vertex_xs.append(vertex_x)\n",
    "            vertex_y = data['cropHintsAnnotation']['cropHints'][0]['boundingPoly']['vertices'][2]['y']\n",
    "            vertex_ys.append(vertex_y)\n",
    "            bounding_confidence = data['cropHintsAnnotation']['cropHints'][0]['confidence']\n",
    "            bounding_confidences.append(bounding_confidence)\n",
    "            bounding_importance_frac = data['cropHintsAnnotation']['cropHints'][0].get('importanceFraction', -1)\n",
    "            bounding_importance_fracs.append(bounding_importance_frac)\n",
    "            dominant_blue = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['color']['blue']\n",
    "            dominant_blues.append(dominant_blue)\n",
    "            dominant_green = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['color']['green']\n",
    "            dominant_greens.append(dominant_green)\n",
    "            dominant_red = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['color']['red']\n",
    "            dominant_reds.append(dominant_red)\n",
    "            dominant_pixel_frac = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['pixelFraction']\n",
    "            dominant_pixel_fracs.append(dominant_pixel_frac)\n",
    "            dominant_score = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['score']\n",
    "            dominant_scores.append(dominant_score)\n",
    "            if data.get('labelAnnotations'):\n",
    "                label_score = data['labelAnnotations'][0]['score']\n",
    "                label_scores.append(label_score)\n",
    "            else:\n",
    "                nl_count += 1\n",
    "                label_scores.append(-1)\n",
    "        except FileNotFoundError:\n",
    "            nf_count += 1\n",
    "            vertex_xs.append(-1)\n",
    "            vertex_ys.append(-1)\n",
    "            bounding_confidences.append(-1)\n",
    "            bounding_importance_fracs.append(-1)\n",
    "            dominant_blues.append(-1)\n",
    "            dominant_greens.append(-1)\n",
    "            dominant_reds.append(-1)\n",
    "            dominant_pixel_fracs.append(-1)\n",
    "            dominant_scores.append(-1)\n",
    "            label_scores.append(-1)\n",
    "\n",
    "    print(nf_count)\n",
    "    print(nl_count)\n",
    "    df.loc[:, 'vertex_x'] = vertex_xs\n",
    "    df.loc[:, 'vertex_y'] = vertex_ys\n",
    "    df.loc[:, 'bounding_confidence'] = bounding_confidences\n",
    "    df.loc[:, 'bounding_importance'] = bounding_importance_fracs\n",
    "    df.loc[:, 'dominant_blue'] = dominant_blues\n",
    "    df.loc[:, 'dominant_green'] = dominant_greens\n",
    "    df.loc[:, 'dominant_red'] = dominant_reds\n",
    "    df.loc[:, 'dominant_pixel_frac'] = dominant_pixel_fracs\n",
    "    df.loc[:, 'dominant_score'] = dominant_scores\n",
    "    df.loc[:, 'label_score'] = label_scores\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14993/14993 [00:04<00:00, 3633.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df = add_image_metadata_features(train_df, 'PetID', input_path + '/train_metadata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3948/3948 [00:01<00:00, 3411.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_df = add_image_metadata_features(test_df, 'PetID', input_path + '/test_metadata')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate simple (without words embeddings) features based on 'Description'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_text_length(df, text_column='Description'):\n",
    "    df[text_column+'Length'] = df[text_column].fillna(\" \").apply(lambda x: len(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_number_of_words(df, text_column='Description'):\n",
    "    df['NumberOfWords'] = df[text_column].fillna(\" \").apply(lambda x: len(x.split()))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_average_word_length(df, text_length_col='DescriptionLength', number_of_words_col='NumberOfWords'):\n",
    "    \n",
    "    df['AverageWordLength'] = df[text_length_col] / df[number_of_words_col]\n",
    "    df['AverageWordLength'] = df['AverageWordLength'].replace([np.inf, -np.inf], 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_simple_text_features(df, text_column='Description'):\n",
    "    df = add_text_length(df, text_column)\n",
    "    df = add_number_of_words(df, text_column)\n",
    "    df = add_average_word_length(df, 'DescriptionLength', 'NumberOfWords')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = add_simple_text_features(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = add_simple_text_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF features from description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVD_COMPONENTS = 120\n",
    "\n",
    "train_desc = train_df.Description.fillna(\"none\").values\n",
    "test_desc = test_df.Description.fillna(\"none\").values\n",
    "\n",
    "tfv = TfidfVectorizer(min_df=3,  max_features=10000,\n",
    "        strip_accents='unicode', analyzer='word', token_pattern=r'\\w{1,}',\n",
    "        ngram_range=(1, 3), use_idf=1, smooth_idf=1, sublinear_tf=1,\n",
    "        stop_words = 'english')\n",
    "    \n",
    "# Fit TFIDF\n",
    "tfv.fit(list(train_desc))\n",
    "X_tf_idf =  tfv.transform(train_desc)\n",
    "X_test_tf_idf = tfv.transform(test_desc)\n",
    "\n",
    "svd = TruncatedSVD(n_components=SVD_COMPONENTS)\n",
    "svd.fit(X_tf_idf)\n",
    "# print(svd.explained_variance_ratio_.sum())\n",
    "# print(svd.explained_variance_ratio_)\n",
    "X_tf_idf = svd.transform(X_tf_idf)\n",
    "X_tf_idf = pd.DataFrame(X_tf_idf, columns=['svd_{}'.format(i) for i in range(SVD_COMPONENTS)])\n",
    "train_df = pd.concat((train_df, X_tf_idf), axis=1)\n",
    "X_test_tf_idf = svd.transform(X_test_tf_idf)\n",
    "X_test_tf_idf = pd.DataFrame(X_test_tf_idf, columns=['svd_{}'.format(i) for i in range(SVD_COMPONENTS)])\n",
    "test_df = pd.concat((test_df, X_test_tf_idf), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop not-using features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop text features and hash id`s\n",
    "drop_list = ['PetID', \n",
    "             'RescuerID', \n",
    "             'Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_id_test = test_df['PetID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['AdoptionSpeed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(drop_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X.drop('AdoptionSpeed', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df.drop(drop_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select cat features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_indeces_from_names(df,name_list):\n",
    "    indeces = []\n",
    "    for name in name_list:\n",
    "        indeces.append(df.columns.get_loc(name))\n",
    "    return indeces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feature_names = [\n",
    "    'Type',\n",
    "    'Breed1',\n",
    "    'Breed2',\n",
    "    'Gender',\n",
    "    'Color1',\n",
    "    'Color2',\n",
    "    'Color3',\n",
    "#     'Vaccinated',\n",
    "#     'Dewormed',\n",
    "#     'Sterilized',\n",
    "    'Health',\n",
    "    'State',\n",
    "    'No_name',\n",
    "    'Bad_name'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_feature(df, encoder, cat_column_name):\n",
    "    one_hot_arr = encoder.transform(df[cat_column_name].values.reshape(-1,1)).toarray()\n",
    "    one_hot_df = pd.DataFrame(one_hot_arr, \n",
    "                              columns = [cat_column_name+\"_\"+str(int(i)) for i in range(one_hot_arr.shape[1])])\n",
    "    df = pd.concat([df, one_hot_df], axis=1)\n",
    "    df = df.drop([cat_column_name], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for feature in cat_feature_names:\n",
    "#     one_hot_enc = OneHotEncoder()\n",
    "#     values = X[feature].values.reshape(-1, 1).tolist() + X_test[feature].values.reshape(-1, 1).tolist()\n",
    "#     one_hot_enc.fit(values)\n",
    "#     X = one_hot_feature(X, one_hot_enc, feature)\n",
    "#     X_test = one_hot_feature(X_test, one_hot_enc, feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Breed2</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>Color3</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>...</th>\n",
       "      <th>svd_110</th>\n",
       "      <th>svd_111</th>\n",
       "      <th>svd_112</th>\n",
       "      <th>svd_113</th>\n",
       "      <th>svd_114</th>\n",
       "      <th>svd_115</th>\n",
       "      <th>svd_116</th>\n",
       "      <th>svd_117</th>\n",
       "      <th>svd_118</th>\n",
       "      <th>svd_119</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Nibble</td>\n",
       "      <td>3</td>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012845</td>\n",
       "      <td>-0.015627</td>\n",
       "      <td>-0.010596</td>\n",
       "      <td>-0.006852</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.025671</td>\n",
       "      <td>-0.021531</td>\n",
       "      <td>0.074332</td>\n",
       "      <td>-0.051983</td>\n",
       "      <td>0.075864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>No Name Yet</td>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002697</td>\n",
       "      <td>0.048393</td>\n",
       "      <td>-0.055310</td>\n",
       "      <td>0.019588</td>\n",
       "      <td>0.015240</td>\n",
       "      <td>-0.046826</td>\n",
       "      <td>0.023132</td>\n",
       "      <td>0.078573</td>\n",
       "      <td>-0.021171</td>\n",
       "      <td>-0.032533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Brisco</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041545</td>\n",
       "      <td>0.007350</td>\n",
       "      <td>0.029583</td>\n",
       "      <td>-0.028565</td>\n",
       "      <td>0.003216</td>\n",
       "      <td>-0.035025</td>\n",
       "      <td>-0.062875</td>\n",
       "      <td>0.054596</td>\n",
       "      <td>-0.051385</td>\n",
       "      <td>-0.020745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Miko</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005368</td>\n",
       "      <td>-0.020707</td>\n",
       "      <td>0.054453</td>\n",
       "      <td>-0.012310</td>\n",
       "      <td>0.002906</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>-0.001144</td>\n",
       "      <td>-0.024058</td>\n",
       "      <td>-0.019064</td>\n",
       "      <td>-0.006620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046734</td>\n",
       "      <td>-0.032957</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>0.011123</td>\n",
       "      <td>-0.041837</td>\n",
       "      <td>-0.001033</td>\n",
       "      <td>-0.016111</td>\n",
       "      <td>-0.004028</td>\n",
       "      <td>0.008625</td>\n",
       "      <td>-0.004540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type         Name  Age  Breed1  Breed2  Gender  Color1  Color2  Color3  \\\n",
       "0     2       Nibble    3     299       0       1       1       7       0   \n",
       "1     2  No Name Yet    1     265       0       1       1       2       0   \n",
       "2     1       Brisco    1     307       0       1       2       7       0   \n",
       "3     1         Miko    4     307       0       2       1       2       0   \n",
       "4     1       Hunter    1     307       0       1       1       0       0   \n",
       "\n",
       "   MaturitySize    ...      svd_110   svd_111   svd_112   svd_113   svd_114  \\\n",
       "0             1    ...     0.012845 -0.015627 -0.010596 -0.006852  0.000457   \n",
       "1             2    ...     0.002697  0.048393 -0.055310  0.019588  0.015240   \n",
       "2             2    ...    -0.041545  0.007350  0.029583 -0.028565  0.003216   \n",
       "3             2    ...     0.005368 -0.020707  0.054453 -0.012310  0.002906   \n",
       "4             2    ...     0.046734 -0.032957  0.001860  0.011123 -0.041837   \n",
       "\n",
       "    svd_115   svd_116   svd_117   svd_118   svd_119  \n",
       "0  0.025671 -0.021531  0.074332 -0.051983  0.075864  \n",
       "1 -0.046826  0.023132  0.078573 -0.021171 -0.032533  \n",
       "2 -0.035025 -0.062875  0.054596 -0.051385 -0.020745  \n",
       "3  0.001098 -0.001144 -0.024058 -0.019064 -0.006620  \n",
       "4 -0.001033 -0.016111 -0.004028  0.008625 -0.004540  \n",
       "\n",
       "[5 rows x 158 columns]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Breed2</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>Color3</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>...</th>\n",
       "      <th>svd_110</th>\n",
       "      <th>svd_111</th>\n",
       "      <th>svd_112</th>\n",
       "      <th>svd_113</th>\n",
       "      <th>svd_114</th>\n",
       "      <th>svd_115</th>\n",
       "      <th>svd_116</th>\n",
       "      <th>svd_117</th>\n",
       "      <th>svd_118</th>\n",
       "      <th>svd_119</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Puppy</td>\n",
       "      <td>2</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006423</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>-0.012746</td>\n",
       "      <td>-0.017503</td>\n",
       "      <td>-0.016944</td>\n",
       "      <td>-0.028383</td>\n",
       "      <td>0.026395</td>\n",
       "      <td>0.005962</td>\n",
       "      <td>0.024403</td>\n",
       "      <td>-0.004923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>London</td>\n",
       "      <td>24</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027410</td>\n",
       "      <td>-0.018066</td>\n",
       "      <td>-0.029473</td>\n",
       "      <td>-0.023839</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>0.030051</td>\n",
       "      <td>0.001376</td>\n",
       "      <td>0.001437</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>-0.016338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Snowball</td>\n",
       "      <td>20</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020269</td>\n",
       "      <td>0.014531</td>\n",
       "      <td>0.038634</td>\n",
       "      <td>-0.020226</td>\n",
       "      <td>0.037579</td>\n",
       "      <td>-0.022691</td>\n",
       "      <td>-0.028332</td>\n",
       "      <td>-0.014153</td>\n",
       "      <td>0.022717</td>\n",
       "      <td>-0.003017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Malibu</td>\n",
       "      <td>5</td>\n",
       "      <td>266</td>\n",
       "      <td>252</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041328</td>\n",
       "      <td>-0.053199</td>\n",
       "      <td>-0.036413</td>\n",
       "      <td>-0.015732</td>\n",
       "      <td>0.029373</td>\n",
       "      <td>0.049163</td>\n",
       "      <td>0.005736</td>\n",
       "      <td>-0.034549</td>\n",
       "      <td>-0.043008</td>\n",
       "      <td>-0.006494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Lala Girl</td>\n",
       "      <td>6</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011001</td>\n",
       "      <td>-0.037103</td>\n",
       "      <td>-0.032843</td>\n",
       "      <td>-0.076949</td>\n",
       "      <td>0.005368</td>\n",
       "      <td>-0.008383</td>\n",
       "      <td>-0.022268</td>\n",
       "      <td>0.011688</td>\n",
       "      <td>-0.021399</td>\n",
       "      <td>0.013594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 157 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type       Name  Age  Breed1  Breed2  Gender  Color1  Color2  Color3  \\\n",
       "0     1      Puppy    2     307       0       1       1       0       0   \n",
       "1     2     London   24     266       0       1       2       7       0   \n",
       "2     2   Snowball   20     266       0       2       7       0       0   \n",
       "3     2     Malibu    5     266     252       2       1       6       7   \n",
       "4     1  Lala Girl    6     307       0       2       1       2       7   \n",
       "\n",
       "   MaturitySize    ...      svd_110   svd_111   svd_112   svd_113   svd_114  \\\n",
       "0             2    ...    -0.006423  0.001366 -0.012746 -0.017503 -0.016944   \n",
       "1             2    ...     0.027410 -0.018066 -0.029473 -0.023839  0.001116   \n",
       "2             2    ...    -0.020269  0.014531  0.038634 -0.020226  0.037579   \n",
       "3             2    ...     0.041328 -0.053199 -0.036413 -0.015732  0.029373   \n",
       "4             2    ...    -0.011001 -0.037103 -0.032843 -0.076949  0.005368   \n",
       "\n",
       "    svd_115   svd_116   svd_117   svd_118   svd_119  \n",
       "0 -0.028383  0.026395  0.005962  0.024403 -0.004923  \n",
       "1  0.030051  0.001376  0.001437  0.002930 -0.016338  \n",
       "2 -0.022691 -0.028332 -0.014153  0.022717 -0.003017  \n",
       "3  0.049163  0.005736 -0.034549 -0.043008 -0.006494  \n",
       "4 -0.008383 -0.022268  0.011688 -0.021399  0.013594  \n",
       "\n",
       "[5 rows x 157 columns]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create cd and pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(['Name', 'AdoptionSpeed'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Breed2</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>Color3</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>FurLength</th>\n",
       "      <th>...</th>\n",
       "      <th>svd_110</th>\n",
       "      <th>svd_111</th>\n",
       "      <th>svd_112</th>\n",
       "      <th>svd_113</th>\n",
       "      <th>svd_114</th>\n",
       "      <th>svd_115</th>\n",
       "      <th>svd_116</th>\n",
       "      <th>svd_117</th>\n",
       "      <th>svd_118</th>\n",
       "      <th>svd_119</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012845</td>\n",
       "      <td>-0.015627</td>\n",
       "      <td>-0.010596</td>\n",
       "      <td>-0.006852</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.025671</td>\n",
       "      <td>-0.021531</td>\n",
       "      <td>0.074332</td>\n",
       "      <td>-0.051983</td>\n",
       "      <td>0.075864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002697</td>\n",
       "      <td>0.048393</td>\n",
       "      <td>-0.055310</td>\n",
       "      <td>0.019588</td>\n",
       "      <td>0.015240</td>\n",
       "      <td>-0.046826</td>\n",
       "      <td>0.023132</td>\n",
       "      <td>0.078573</td>\n",
       "      <td>-0.021171</td>\n",
       "      <td>-0.032533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041545</td>\n",
       "      <td>0.007350</td>\n",
       "      <td>0.029583</td>\n",
       "      <td>-0.028565</td>\n",
       "      <td>0.003216</td>\n",
       "      <td>-0.035025</td>\n",
       "      <td>-0.062875</td>\n",
       "      <td>0.054596</td>\n",
       "      <td>-0.051385</td>\n",
       "      <td>-0.020745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005368</td>\n",
       "      <td>-0.020707</td>\n",
       "      <td>0.054453</td>\n",
       "      <td>-0.012310</td>\n",
       "      <td>0.002906</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>-0.001144</td>\n",
       "      <td>-0.024058</td>\n",
       "      <td>-0.019064</td>\n",
       "      <td>-0.006620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046734</td>\n",
       "      <td>-0.032957</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>0.011123</td>\n",
       "      <td>-0.041837</td>\n",
       "      <td>-0.001033</td>\n",
       "      <td>-0.016111</td>\n",
       "      <td>-0.004028</td>\n",
       "      <td>0.008625</td>\n",
       "      <td>-0.004540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 156 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type  Age  Breed1  Breed2  Gender  Color1  Color2  Color3  MaturitySize  \\\n",
       "0     2    3     299       0       1       1       7       0             1   \n",
       "1     2    1     265       0       1       1       2       0             2   \n",
       "2     1    1     307       0       1       2       7       0             2   \n",
       "3     1    4     307       0       2       1       2       0             2   \n",
       "4     1    1     307       0       1       1       0       0             2   \n",
       "\n",
       "   FurLength    ...      svd_110   svd_111   svd_112   svd_113   svd_114  \\\n",
       "0          1    ...     0.012845 -0.015627 -0.010596 -0.006852  0.000457   \n",
       "1          2    ...     0.002697  0.048393 -0.055310  0.019588  0.015240   \n",
       "2          2    ...    -0.041545  0.007350  0.029583 -0.028565  0.003216   \n",
       "3          1    ...     0.005368 -0.020707  0.054453 -0.012310  0.002906   \n",
       "4          1    ...     0.046734 -0.032957  0.001860  0.011123 -0.041837   \n",
       "\n",
       "    svd_115   svd_116   svd_117   svd_118   svd_119  \n",
       "0  0.025671 -0.021531  0.074332 -0.051983  0.075864  \n",
       "1 -0.046826  0.023132  0.078573 -0.021171 -0.032533  \n",
       "2 -0.035025 -0.062875  0.054596 -0.051385 -0.020745  \n",
       "3  0.001098 -0.001144 -0.024058 -0.019064 -0.006620  \n",
       "4 -0.001033 -0.016111 -0.004028  0.008625 -0.004540  \n",
       "\n",
       "[5 rows x 156 columns]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.drop(['Name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(X, y, n_splits):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=False, random_state=RANDOM_STATE)\n",
    "    test_predictions = np.zeros((X_test.shape[0], 1))\n",
    "    train_predictions = np.zeros((X.shape[0], 1))\n",
    "\n",
    "    cv_results = []\n",
    "    scores = []\n",
    "    coefficients = np.zeros((n_splits, 4))\n",
    "    fold = 0\n",
    "    for tr_ind, val_ind in skf.split(X, y):\n",
    "        X_train = X.loc[tr_ind]\n",
    "        y_train = y.loc[tr_ind]\n",
    "        \n",
    "        X_valid = X.loc[val_ind]\n",
    "        y_valid = y.loc[val_ind]\n",
    "        \n",
    "        lgb_params = {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'learning_rate': 0.005,\n",
    "            'subsample': .8,\n",
    "            'colsample_bytree': 0.8,\n",
    "            'min_split_gain': 0.006,\n",
    "            'min_child_samples': 150,\n",
    "            'min_child_weight': 0.1,\n",
    "            'max_depth': 20,\n",
    "            'n_estimators': 10000,\n",
    "            'num_leaves': 80,\n",
    "            'silent': -1,\n",
    "            'verbose': -1,\n",
    "            'random_state': RANDOM_STATE\n",
    "        }\n",
    "        \n",
    "        model = lgb.LGBMRegressor(**lgb_params)\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_valid, y_valid)],\n",
    "            eval_metric='rmse',\n",
    "            verbose=200,\n",
    "            early_stopping_rounds=100\n",
    "        )\n",
    "        \n",
    "        y_pred = model.predict(X_valid, num_iteration=model.best_iteration_)\n",
    "#         y_pred = list(map(lambda x: int(x[0]), y_pred))\n",
    "        test_pred = model.predict(X_test, num_iteration=model.best_iteration_)\n",
    "        test_predictions += test_pred.reshape(-1, 1)\n",
    "        \n",
    "        train_predictions[val_ind] = y_pred.reshape(-1, 1)\n",
    "\n",
    "        \n",
    "        optR = OptimizedRounder()\n",
    "        optR.fit(y_pred, y_valid.values)\n",
    "        coefficients[fold, :] = optR.coefficients()\n",
    "        \n",
    "        pred = optR.predict(y_pred, coefficients[fold, :])\n",
    "        \n",
    "        kappa_scr = quadratic_weighted_kappa(y_valid, pred)\n",
    "        \n",
    "        print(\"Fold = {}. QWK = {}. Coef = {}\".format(fold, kappa_scr, coefficients[fold,:]))\n",
    "        cv_result = {}\n",
    "        cv_result['Fold'] = fold\n",
    "        cv_result['Model'] = model\n",
    "        cv_result['QWK'] = kappa_scr\n",
    "        cv_result['Coef'] = coefficients[fold, :]\n",
    "        cv_results.append(cv_result)\n",
    "        scores.append(kappa_scr)\n",
    "        fold += 1\n",
    "    print('Average: {}'.format(sum(scores)/n_splits))\n",
    "    test_predictions = test_predictions * 1./n_splits\n",
    "\n",
    "    return {\n",
    "            'train_predictions': train_predictions,\n",
    "            'predictions': test_predictions,\n",
    "            'coefficients': np.mean(coefficients, axis=0)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's rmse: 1.10193\tvalid_0's l2: 1.21425\n",
      "[400]\tvalid_0's rmse: 1.07841\tvalid_0's l2: 1.16297\n",
      "[600]\tvalid_0's rmse: 1.06791\tvalid_0's l2: 1.14043\n",
      "[800]\tvalid_0's rmse: 1.0611\tvalid_0's l2: 1.12593\n",
      "[1000]\tvalid_0's rmse: 1.0566\tvalid_0's l2: 1.1164\n",
      "[1200]\tvalid_0's rmse: 1.05368\tvalid_0's l2: 1.11023\n",
      "[1400]\tvalid_0's rmse: 1.05188\tvalid_0's l2: 1.10644\n",
      "[1600]\tvalid_0's rmse: 1.05048\tvalid_0's l2: 1.1035\n",
      "[1800]\tvalid_0's rmse: 1.04931\tvalid_0's l2: 1.10105\n",
      "[2000]\tvalid_0's rmse: 1.04838\tvalid_0's l2: 1.0991\n",
      "[2200]\tvalid_0's rmse: 1.04799\tvalid_0's l2: 1.09828\n",
      "[2400]\tvalid_0's rmse: 1.04772\tvalid_0's l2: 1.09771\n",
      "[2600]\tvalid_0's rmse: 1.04733\tvalid_0's l2: 1.09691\n",
      "[2800]\tvalid_0's rmse: 1.04689\tvalid_0's l2: 1.09597\n",
      "[3000]\tvalid_0's rmse: 1.04641\tvalid_0's l2: 1.09497\n",
      "[3200]\tvalid_0's rmse: 1.04605\tvalid_0's l2: 1.09423\n",
      "[3400]\tvalid_0's rmse: 1.0457\tvalid_0's l2: 1.09349\n",
      "[3600]\tvalid_0's rmse: 1.04551\tvalid_0's l2: 1.09309\n",
      "[3800]\tvalid_0's rmse: 1.04539\tvalid_0's l2: 1.09284\n",
      "[4000]\tvalid_0's rmse: 1.04531\tvalid_0's l2: 1.09268\n",
      "Early stopping, best iteration is:\n",
      "[3930]\tvalid_0's rmse: 1.04525\tvalid_0's l2: 1.09255\n",
      "Fold = 0. QWK = 0.4190868466089599. Coef = [0.5076849  1.75589593 2.52435816 2.8330906 ]\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's rmse: 1.09706\tvalid_0's l2: 1.20354\n",
      "[400]\tvalid_0's rmse: 1.07109\tvalid_0's l2: 1.14724\n",
      "[600]\tvalid_0's rmse: 1.05841\tvalid_0's l2: 1.12024\n",
      "[800]\tvalid_0's rmse: 1.05184\tvalid_0's l2: 1.10636\n",
      "[1000]\tvalid_0's rmse: 1.04742\tvalid_0's l2: 1.09708\n",
      "[1200]\tvalid_0's rmse: 1.04532\tvalid_0's l2: 1.09269\n",
      "[1400]\tvalid_0's rmse: 1.04391\tvalid_0's l2: 1.08976\n",
      "[1600]\tvalid_0's rmse: 1.04252\tvalid_0's l2: 1.08684\n",
      "[1800]\tvalid_0's rmse: 1.04167\tvalid_0's l2: 1.08508\n",
      "[2000]\tvalid_0's rmse: 1.04126\tvalid_0's l2: 1.08422\n",
      "[2200]\tvalid_0's rmse: 1.04087\tvalid_0's l2: 1.08342\n",
      "[2400]\tvalid_0's rmse: 1.04045\tvalid_0's l2: 1.08254\n",
      "[2600]\tvalid_0's rmse: 1.03996\tvalid_0's l2: 1.08151\n",
      "[2800]\tvalid_0's rmse: 1.0395\tvalid_0's l2: 1.08055\n",
      "[3000]\tvalid_0's rmse: 1.03921\tvalid_0's l2: 1.07996\n",
      "[3200]\tvalid_0's rmse: 1.03895\tvalid_0's l2: 1.07941\n",
      "Early stopping, best iteration is:\n",
      "[3278]\tvalid_0's rmse: 1.03886\tvalid_0's l2: 1.07923\n",
      "Fold = 1. QWK = 0.44700487114842735. Coef = [0.48377642 2.07951783 2.51141459 2.98973504]\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's rmse: 1.10004\tvalid_0's l2: 1.2101\n",
      "[400]\tvalid_0's rmse: 1.07609\tvalid_0's l2: 1.15798\n",
      "[600]\tvalid_0's rmse: 1.06556\tvalid_0's l2: 1.13541\n",
      "[800]\tvalid_0's rmse: 1.0588\tvalid_0's l2: 1.12106\n",
      "[1000]\tvalid_0's rmse: 1.05522\tvalid_0's l2: 1.11349\n",
      "[1200]\tvalid_0's rmse: 1.05249\tvalid_0's l2: 1.10774\n",
      "[1400]\tvalid_0's rmse: 1.05063\tvalid_0's l2: 1.10382\n",
      "[1600]\tvalid_0's rmse: 1.04924\tvalid_0's l2: 1.1009\n",
      "[1800]\tvalid_0's rmse: 1.0486\tvalid_0's l2: 1.09956\n",
      "[2000]\tvalid_0's rmse: 1.04797\tvalid_0's l2: 1.09824\n",
      "[2200]\tvalid_0's rmse: 1.04739\tvalid_0's l2: 1.09703\n",
      "[2400]\tvalid_0's rmse: 1.04701\tvalid_0's l2: 1.09623\n",
      "[2600]\tvalid_0's rmse: 1.04669\tvalid_0's l2: 1.09557\n",
      "Early stopping, best iteration is:\n",
      "[2617]\tvalid_0's rmse: 1.04662\tvalid_0's l2: 1.09542\n",
      "Fold = 2. QWK = 0.41162244813864235. Coef = [0.49476344 1.82766491 2.52596485 2.99459031]\n",
      "Average: 0.4259047219653432\n"
     ]
    }
   ],
   "source": [
    "results = cross_val(X, y, n_splits = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.79588282]\n",
      " [2.93990883]\n",
      " [2.92158327]\n",
      " ...\n",
      " [1.41564543]\n",
      " [1.87354248]\n",
      " [2.70175199]]\n"
     ]
    }
   ],
   "source": [
    "print(results['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "optR = OptimizedRounder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = np.array(list(map(lambda x: x[0], results['train_predictions'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "optR.fit(train_predictions, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = optR.coefficients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.47835911, 2.07812264, 2.50880788, 2.83760833])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = optR.predict(results['predictions'], coefficients).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = list(map(lambda x: x[0], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = pd.read_csv(os.path.join(input_path, 'test/sample_submission.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df.AdoptionSpeed = predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    1225\n",
       "4    1042\n",
       "3     909\n",
       "1     772\n",
       "Name: AdoptionSpeed, dtype: int64"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_df.AdoptionSpeed.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PetID</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>378fcc4fc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73c10e136</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72000c4c5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e147a4b9f</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43fbba852</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PetID  AdoptionSpeed\n",
       "0  378fcc4fc              1\n",
       "1  73c10e136              4\n",
       "2  72000c4c5              4\n",
       "3  e147a4b9f              3\n",
       "4  43fbba852              4"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
